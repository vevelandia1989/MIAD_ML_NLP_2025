{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construcción e implementación de modelos con métodos de ensamblajes  \n",
    "\n",
    "En este notebook aprenderá a construir e implementar dos métodos de ensamblaje (bagging y combinación de modelos), desarrollando el código manualmente y  usando la librería especializada sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones Generales:\n",
    "\n",
    "Por una parte, los modelos con Bagging que construirá por medio de este notebook deberán predecir el precio de un automóvil dadas diferentes características. Por otra parte, los métodos de combinación de modelos debera predecir si un usuario deja o no de usar los servicios de una compañía (churn) teniendo en cuenta diferentes variables. Para conocer más detalles de la base de 'churn' puede ingresar al siguiente vínculo: http://srepho.github.io/Churn/Churn\n",
    "   \n",
    "Para realizar la actividad, solo siga las indicaciones asociadas a cada celda del notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar base de datos y librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas==2.2.3 numpy==2.0.2 matplotlib==3.9.4 scikit-learn==1.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos de archivos .csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Datos de entremiento\n",
    "url = 'https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/vehicles_train.csv'\n",
    "train = pd.read_csv(url)\n",
    "train['vtype'] = train.vtype.map({'car':0, 'truck':1})\n",
    "\n",
    "# Datos de evaluación (test)\n",
    "url = 'https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/vehicles_test.csv'\n",
    "test = pd.read_csv(url)\n",
    "test['vtype'] = test.vtype.map({'car':0, 'truck':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impresión de 5 observaciones del set de entrenamiento\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar diferentes modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Definición de 4 modelos diferentes: regresión logística, árbol de decisión,Navie Bayes y k vecinos más cercanos\n",
    "models = {'lr': LinearRegression(),\n",
    "          'dt': DecisionTreeRegressor(),\n",
    "          'nb': GaussianNB(),\n",
    "          'kn': KNeighborsRegressor()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y) en set de entrenamiento y test\n",
    "X_train = train.iloc[:, 1:]\n",
    "X_test = test.iloc[:, 1:]\n",
    "y_train = train.price\n",
    "y_test = test.price\n",
    "\n",
    "# Entrenamiento (fit) de cada modelo\n",
    "for model in models.keys():\n",
    "    models[model].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción de las observaciones del set de test para cada modelo\n",
    "y_pred = pd.DataFrame(index=test.index, columns=models.keys())\n",
    "for model in models.keys():\n",
    "    y_pred[model] = models[model].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del error de cada modelo\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for model in models.keys():\n",
    "    print(model,np.sqrt(mean_squared_error(y_pred[model], y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación  del error promedio de las predicciones\n",
    "np.sqrt(mean_squared_error(y_pred.mean(axis=1), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un arreglo de 1 a 20\n",
    "np.random.seed(1)\n",
    "\n",
    "# Impresión de arreglo y muestreo aleatorio\n",
    "nums = np.arange(1, 21)\n",
    "print('Arreglo:', nums)\n",
    "print('Muestreo aleatorio: ', np.random.choice(a=nums, size=20, replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de 10 muestras de bootstrap \n",
    "np.random.seed(123)\n",
    "\n",
    "n_samples = train.shape[0]\n",
    "n_B = 10\n",
    "\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(1, n_B +1 )]\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización muestra boostrap #1 para entremiento\n",
    "train.iloc[samples[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción un árbol de decisión para cada muestra boostrap\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Definición del modelo usando DecisionTreeRegressor de sklearn\n",
    "treereg = DecisionTreeRegressor(max_depth=None, random_state=123)\n",
    "\n",
    "# DataFrame para guardar las predicciones de cada árbol\n",
    "y_pred = pd.DataFrame(index=test.index, columns=[list(range(n_B))])\n",
    "\n",
    "# Entrenamiento de un árbol sobre cada muestra boostrap y predicción sobre los datos de test\n",
    "for i, sample in enumerate(samples):\n",
    "    X_train = train.iloc[sample, 1:]\n",
    "    y_train = train.iloc[sample, 0]\n",
    "    treereg.fit(X_train, y_train)\n",
    "    y_pred.iloc[:,i] = treereg.predict(X_test)\n",
    "    \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desempeño de cada árbol\n",
    "for i in range(n_B):\n",
    "    print('Árbol ', i, 'tiene un error: ', np.sqrt(mean_squared_error(y_pred.iloc[:,i], y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones promedio para cada obserbación del set de test\n",
    "y_pred.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error al promediar las predicciones de todos los árboles\n",
    "np.sqrt(mean_squared_error(y_test, y_pred.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging con sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y) en set de entrenamiento y test\n",
    "X_train = train.iloc[:, 1:]\n",
    "y_train = train.iloc[:, 0]\n",
    "X_test = test.iloc[:, 1:]\n",
    "y_test = test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso de BaggingRegressor de la libreria (sklearn) donde se usa el modelo DecisionTreeRegressor como estimador\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagreg = BaggingRegressor(DecisionTreeRegressor(), n_estimators=500, \n",
    "                          bootstrap=True, oob_score=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenemiento del modelo con set de entrenamiento y predicción en el set de test\n",
    "bagreg.fit(X_train, y_train)\n",
    "y_pred = bagreg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo del error del modelo\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimar el error out-of-sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la primera muestra de bootstrap\n",
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de las observaciones dentro de la bolsa \"in-bag\" para cada muestra\n",
    "for sample in samples:\n",
    "    print(set(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de las observaciones fuera de la bolsa \"out-of-bag\" para cada muestra\n",
    "for sample in samples:\n",
    "    print(sorted(set(range(n_samples)) - set(sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo del error the out-of-bag con el R-cuadrado (no con el MSE)\n",
    "bagreg.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinación de clasificadores - Votación mayoritaria manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carga de datos de archivos .csv\n",
    "url = 'https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/churn.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Separación de variables predictoras (X) y variable de interés (y)\n",
    "\n",
    "# Seleción de variables numéricas\n",
    "X = data.iloc[:, [1,2,6,7,8,9,10]].astype(np.float64)\n",
    "X = X.join((data.iloc[:, [4,5]] == 'no').astype(np.float64))\n",
    "\n",
    "y = (data.iloc[:, -1] == 'True.').astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impresión datos\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proporciones de las diferentes clases de variable de interés (y)\n",
    "y.value_counts().to_frame('count').assign(percentage = lambda x: x/x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Separación de variables predictoras (X) y variable de interés (y) en set de entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de 100 muestras de bootstrap\n",
    "n_estimators = 100\n",
    "np.random.seed(123)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(n_estimators)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento de 100 modelos con las 100 muestras boostrap\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "np.random.seed(123) \n",
    "seeds = np.random.randint(1, 10000, size=n_estimators)\n",
    "\n",
    "trees = {}\n",
    "for i in range(n_estimators):\n",
    "    trees[i] = DecisionTreeClassifier(max_features=\"sqrt\", max_depth=None, random_state=seeds[i])\n",
    "    trees[i].fit(X_train.iloc[samples[i]], y_train.iloc[samples[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción para los datos del set de test con cada modelo\n",
    "y_pred_df = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "for i in range(n_estimators):\n",
    "    y_pred_df.iloc[:, i] = trees[i].predict(X_test)\n",
    "\n",
    "y_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impresión de la cantidad de modelos que predijeron 1 para 10 observaciones\n",
    "y_pred_df.sum(axis=1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votación mayoritaria\n",
    "y_pred = (y_pred_df.sum(axis=1) >= (n_estimators / 2)).astype(np.int64)\n",
    "\n",
    "# Desempeño al hacer votación mayoritaria\n",
    "from sklearn import metrics\n",
    "metrics.f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desempeño al hacer votación mayoritaria\n",
    "metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinación de clasificadores - Votación mayoritaria con sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del modelo BaggingClassifier de la libreria sklearn\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción y desempeño al hacer votación mayoritaria\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinación de clasificadores - Votación ponderada manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_oob = []\n",
    "# Obtención de las observaciones fuera de la bolsa \"out-of-bag\" para cada muestra\n",
    "for sample in samples:\n",
    "    samples_oob.append(sorted(set(range(n_samples)) - set(sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimación de los errores OOB para cada clasificador\n",
    "errors = np.zeros(n_estimators)\n",
    "\n",
    "for i in range(n_estimators):\n",
    "    y_pred_ = trees[i].predict(X_train.iloc[samples_oob[i]])\n",
    "    errors[i] = 1 - metrics.accuracy_score(y_train.iloc[samples_oob[i]], y_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de OOB para cada árbol\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.scatter(range(n_estimators), errors)\n",
    "plt.xlim([0, n_estimators])\n",
    "plt.title('OOB error of each tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención de los pesos alpha de cada modelo de acuerdo al error OOB\n",
    "alpha = (1 - errors) / (1 - errors).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ponderación de las predicciones con los pesos alpha\n",
    "weighted_sum_1 = ((y_pred_df) * alpha).sum(axis=1)\n",
    "weighted_sum_1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desempeño al hacer votación ponderada\n",
    "y_pred = (weighted_sum_1 >= 0.5).astype(np.int64)\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinación de clasificadores - Votación ponderada con sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del modelo BaggingClassifier de la libreria sklearn\n",
    "clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True)\n",
    "\n",
    "# Predicción y desempeño al hacer votación mayoritaria\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención de los pesos alpha de cada modelo de acuerdo al error OOB\n",
    "errors = np.zeros(clf.n_estimators)\n",
    "y_pred_all_ = np.zeros((X_test.shape[0], clf.n_estimators))\n",
    "\n",
    "for i in range(clf.n_estimators):\n",
    "    oob_sample = ~clf.estimators_samples_[i]\n",
    "    y_pred_ = clf.estimators_[i].predict(X_train.values[oob_sample])\n",
    "    errors[i] = metrics.accuracy_score(y_pred_, y_train.values[oob_sample])\n",
    "    y_pred_all_[:, i] = clf.estimators_[i].predict(X_test)\n",
    "    \n",
    "alpha = (1 - errors) / (1 - errors).sum()\n",
    "y_pred = (np.sum(y_pred_all_ * alpha, axis=1) >= 0.5).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desempeño al hacer votación ponderada\n",
    "metrics.f1_score(y_pred, y_test), metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AQUI EMPIEZA EL DESARROLLO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
