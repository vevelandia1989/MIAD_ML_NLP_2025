{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bbe72ef-eb63-40a6-88e0-bca75023d94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_educacion = pd.read_csv(\"noticias_educacion_sample.csv\")\n",
    "df_educacion['clase'] = 0\n",
    "df_politica = pd.read_csv(\"noticias_politica_sample.csv\")\n",
    "df_politica['clase'] = 1\n",
    "df_deportes = pd.read_csv(\"noticias_deportes_sample.csv\")\n",
    "df_deportes['clase'] = 2\n",
    "df_economia = pd.read_csv(\"noticias_economia_sample.csv\")\n",
    "df_economia['clase'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d903ef95-9bf2-4757-873d-15558a2ebf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>clase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Como parte de la política de puertas abiertas ...</td>\n",
       "      <td>2022-02-08T19:12:01.737Z</td>\n",
       "      <td>La CAN abre convocatorias para pasantías en Co...</td>\n",
       "      <td>La Comunidad Andina de Naciones abrió la posib...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>El programa, que cumple 30 años desde su prime...</td>\n",
       "      <td>2022-05-14T18:02:23.629Z</td>\n",
       "      <td>Colfuturo apoyará a 1.526 profesionales colomb...</td>\n",
       "      <td>Los beneficiarios, en su mayoría, realizaron e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Estudiar una carrera universitaria en Colombia...</td>\n",
       "      <td>2022-10-19T09:45:01.712Z</td>\n",
       "      <td>¿Cómo estudiar becado en la mejor universidad ...</td>\n",
       "      <td>Según el ranking de Times Higher Education, la...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Escuche aquí el episodio número 27 de Finanzas...</td>\n",
       "      <td>2021-04-07T17:56:34.238Z</td>\n",
       "      <td>Consejos para financiar con inteligencia sus e...</td>\n",
       "      <td>Si estudiar es uno de sus principales objetivo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Durante el último año de la carrera universita...</td>\n",
       "      <td>2022-04-02T18:08:22.865Z</td>\n",
       "      <td>Pruebas Saber Pro: el listado de universidades...</td>\n",
       "      <td>Las universidades públicas presentaron preocup...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>495</td>\n",
       "      <td>Colombia sigue aumentando su endeudamiento ext...</td>\n",
       "      <td>2023-02-10T23:08:47.922Z</td>\n",
       "      <td>Deuda externa de Colombia representó el 52,8% ...</td>\n",
       "      <td>Así lo deja en evidencia el más reciente repor...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>496</td>\n",
       "      <td>La Agencia de Estados Unidos para el Desarroll...</td>\n",
       "      <td>2022-09-28T17:00:15.603Z</td>\n",
       "      <td>Lanzan convocatoria para apoyar a más de mil o...</td>\n",
       "      <td>La Usaid estará al frente de este proceso que ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>497</td>\n",
       "      <td>La inflación es uno de los mayores retos que e...</td>\n",
       "      <td>2023-02-25T03:41:20.639Z</td>\n",
       "      <td>Controlar la inflación no será tan fácil como ...</td>\n",
       "      <td>El aumento en los precios será una constante e...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>498</td>\n",
       "      <td>23 lugares icónicos de Cúcuta fueron decorados...</td>\n",
       "      <td>2022-12-07T17:16:46.317Z</td>\n",
       "      <td>Reapertura económica en la frontera: artesanas...</td>\n",
       "      <td>Cúcuta prepara la Ruta Navideña luego de haber...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>499</td>\n",
       "      <td>Durante las últimas semanas los bancos se han ...</td>\n",
       "      <td>2023-03-14T19:22:40.773Z</td>\n",
       "      <td>Tras anuncio del Gobierno Petro, el Banco Agra...</td>\n",
       "      <td>La ministra de Agricultura, Cecilia López, les...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1933 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                            content  \\\n",
       "0         0  Como parte de la política de puertas abiertas ...   \n",
       "1         1  El programa, que cumple 30 años desde su prime...   \n",
       "2         2  Estudiar una carrera universitaria en Colombia...   \n",
       "3         3  Escuche aquí el episodio número 27 de Finanzas...   \n",
       "4         4  Durante el último año de la carrera universita...   \n",
       "...     ...                                                ...   \n",
       "1928    495  Colombia sigue aumentando su endeudamiento ext...   \n",
       "1929    496  La Agencia de Estados Unidos para el Desarroll...   \n",
       "1930    497  La inflación es uno de los mayores retos que e...   \n",
       "1931    498  23 lugares icónicos de Cúcuta fueron decorados...   \n",
       "1932    499  Durante las últimas semanas los bancos se han ...   \n",
       "\n",
       "                          date  \\\n",
       "0     2022-02-08T19:12:01.737Z   \n",
       "1     2022-05-14T18:02:23.629Z   \n",
       "2     2022-10-19T09:45:01.712Z   \n",
       "3     2021-04-07T17:56:34.238Z   \n",
       "4     2022-04-02T18:08:22.865Z   \n",
       "...                        ...   \n",
       "1928  2023-02-10T23:08:47.922Z   \n",
       "1929  2022-09-28T17:00:15.603Z   \n",
       "1930  2023-02-25T03:41:20.639Z   \n",
       "1931  2022-12-07T17:16:46.317Z   \n",
       "1932  2023-03-14T19:22:40.773Z   \n",
       "\n",
       "                                               headline  \\\n",
       "0     La CAN abre convocatorias para pasantías en Co...   \n",
       "1     Colfuturo apoyará a 1.526 profesionales colomb...   \n",
       "2     ¿Cómo estudiar becado en la mejor universidad ...   \n",
       "3     Consejos para financiar con inteligencia sus e...   \n",
       "4     Pruebas Saber Pro: el listado de universidades...   \n",
       "...                                                 ...   \n",
       "1928  Deuda externa de Colombia representó el 52,8% ...   \n",
       "1929  Lanzan convocatoria para apoyar a más de mil o...   \n",
       "1930  Controlar la inflación no será tan fácil como ...   \n",
       "1931  Reapertura económica en la frontera: artesanas...   \n",
       "1932  Tras anuncio del Gobierno Petro, el Banco Agra...   \n",
       "\n",
       "                                            description  clase  \n",
       "0     La Comunidad Andina de Naciones abrió la posib...      0  \n",
       "1     Los beneficiarios, en su mayoría, realizaron e...      0  \n",
       "2     Según el ranking de Times Higher Education, la...      0  \n",
       "3     Si estudiar es uno de sus principales objetivo...      0  \n",
       "4     Las universidades públicas presentaron preocup...      0  \n",
       "...                                                 ...    ...  \n",
       "1928  Así lo deja en evidencia el más reciente repor...      3  \n",
       "1929  La Usaid estará al frente de este proceso que ...      3  \n",
       "1930  El aumento en los precios será una constante e...      3  \n",
       "1931  Cúcuta prepara la Ruta Navideña luego de haber...      3  \n",
       "1932  La ministra de Agricultura, Cecilia López, les...      3  \n",
       "\n",
       "[1933 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_educacion, df_politica, df_deportes, df_economia]).dropna().reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b8110-f05d-4426-b661-681a8bdbe7c5",
   "metadata": {},
   "source": [
    "# BERT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3271a388-c2e6-4411-9792-e049b39ba9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "85/85 [==============================] - 83s 454ms/step - loss: 1.3964 - sparse_categorical_accuracy: 0.2631 - val_loss: 1.3889 - val_sparse_categorical_accuracy: 0.2552\n",
      "Epoch 2/4\n",
      "85/85 [==============================] - 35s 413ms/step - loss: 1.3213 - sparse_categorical_accuracy: 0.3422 - val_loss: 1.1680 - val_sparse_categorical_accuracy: 0.5034\n",
      "Epoch 3/4\n",
      "85/85 [==============================] - 35s 409ms/step - loss: 0.8203 - sparse_categorical_accuracy: 0.6319 - val_loss: 0.6617 - val_sparse_categorical_accuracy: 0.7483\n",
      "Epoch 4/4\n",
      "85/85 [==============================] - 35s 409ms/step - loss: 0.5342 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.5438 - val_sparse_categorical_accuracy: 0.8034\n",
      "19/19 [==============================] - 2s 123ms/step - loss: 0.5328 - sparse_categorical_accuracy: 0.8241\n",
      "\n",
      "Test loss: 0.5328, Test accuracy: 0.8241\n",
      "19/19 [==============================] - 5s 121ms/step\n",
      "Class 0: Precision: 0.83, Recall: 0.89, F1 score: 0.86\n",
      "Class 1: Precision: 0.90, Recall: 0.59, F1 score: 0.72\n",
      "Class 2: Precision: 0.94, Recall: 1.00, F1 score: 0.97\n",
      "Class 3: Precision: 0.67, Recall: 0.81, F1 score: 0.73\n",
      "\n",
      "Predicted class for example text: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 1. Load and prepare your dataset\n",
    "df = df[['content', 'clase']].dropna().reset_index(drop=True)\n",
    "\n",
    "# 2. Split into train/val/test\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['clase'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['clase'], random_state=42)\n",
    "\n",
    "# 3. Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# 4. Tokenization function\n",
    "def encode_texts(texts, labels):\n",
    "    tokens = tokenizer(\n",
    "        list(texts),\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    return tokens, tf.convert_to_tensor(labels)\n",
    "\n",
    "# 5. Encode splits\n",
    "train_tokens, train_labels = encode_texts(train_df['content'], train_df['clase'])\n",
    "val_tokens, val_labels = encode_texts(val_df['content'], val_df['clase'])\n",
    "test_tokens, test_labels = encode_texts(test_df['content'], test_df['clase'])\n",
    "\n",
    "# 6. Create tf.data.Dataset\n",
    "def make_tf_dataset(tokens, labels, batch_size=16, shuffle=False):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(tokens), labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(1000)\n",
    "    return dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "tf_train = make_tf_dataset(train_tokens, train_labels, shuffle=True)\n",
    "tf_val = make_tf_dataset(val_tokens, val_labels)\n",
    "tf_test = make_tf_dataset(test_tokens, test_labels)\n",
    "\n",
    "# 7. Load BERT model\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=4)\n",
    "\n",
    "# 8. Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "# 9. Train\n",
    "model.fit(tf_train, validation_data=tf_val, epochs=4)\n",
    "\n",
    "# 10. Evaluate\n",
    "results = model.evaluate(tf_test)\n",
    "print(f\"\\nTest loss: {results[0]:.4f}, Test accuracy: {results[1]:.4f}\")\n",
    "\n",
    "# 11. Predict on test set\n",
    "y_test = test_labels.numpy()\n",
    "logits = model.predict(tf_test).logits\n",
    "y_pred = np.argmax(logits, axis=1)\n",
    "\n",
    "# 12. Compute precision, recall, F1 score for each class\n",
    "num_classes = len(set(y_test))\n",
    "for i in range(num_classes):\n",
    "    class_predicted = [1 if x == i else 0 for x in y_pred]\n",
    "    class_real = [1 if x == i else 0 for x in y_test]\n",
    "    precision = precision_score(class_real, class_predicted, zero_division=0)\n",
    "    recall = recall_score(class_real, class_predicted, zero_division=0)\n",
    "    f1 = f1_score(class_real, class_predicted, zero_division=0)\n",
    "    print(f\"Class {i}: Precision: {precision:.2f}, Recall: {recall:.2f}, F1 score: {f1:.2f}\")\n",
    "\n",
    "# 13. Optional: Predict on a new sentence\n",
    "test_text = [\"La universidad abrió una nueva convocatoria para becas internacionales.\"]\n",
    "encoded = tokenizer(test_text, truncation=True, padding=True, max_length=128, return_tensors=\"tf\")\n",
    "logits = model(encoded).logits\n",
    "probs = tf.nn.softmax(logits, axis=-1)\n",
    "predicted_class = tf.argmax(probs, axis=1).numpy()[0]\n",
    "print(f\"\\nPredicted class for example text: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7e036c-2e4b-41b6-a527-a2521e7ba377",
   "metadata": {},
   "source": [
    "# GPT-2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349874e1-68aa-49e1-91dd-b241974eab08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 14:46:20.916509: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-22 14:46:20.932744: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747925180.952720   88939 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747925180.958945   88939 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747925180.974985   88939 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747925180.975010   88939 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747925180.975012   88939 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747925180.975014   88939 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-22 14:46:20.980636: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa9303f90184483a0b9884cda4458a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1933 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_88939/1029234103.py:51: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1452' max='1452' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1452/1452 02:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.340800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.941900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.821800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.681700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.596400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.401800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.375100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.359700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.324500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.294600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>3.175700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>3.205600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>3.189300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>3.149500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Generated Text Example:\n",
      "Como parte de la política, las oportunidades especialmente para el pasado 15 de julio en la primera final de la selección del lugar, conocupación y un trino de los grandes grandes que se habilidades. El trino de los grandes se han varios afectados para el año de los parte de los colombianos de los est\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import torch\n",
    "\n",
    "# 1. Load your dataset\n",
    "df = df[['content']].dropna().reset_index(drop=True)\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# 2. Load tokenizer and prepare text\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"content\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "\n",
    "# 3. Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# 4. Data collator for causal LM\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# 5. Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=True,\n",
    "    logging_steps=100,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# 6. Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# 7. Train the model\n",
    "trainer.train()\n",
    "\n",
    "# 8. Save the model\n",
    "trainer.save_model(\"./gpt2-finetuned\")\n",
    "tokenizer.save_pretrained(\"./gpt2-finetuned\")\n",
    "\n",
    "# 9. Generate new text (inference)\n",
    "def generate_text(prompt, max_length=100, temperature=0.9):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    input_ids = input_ids.to(model.device)\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Example generation\n",
    "print(generate_text(\"Como parte de la política\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88d520fb-d1e5-49a7-b637-c720daa15f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gustavo Petro y el Pacto Histórico más de SEMANA por el poco de nada por el Gobierno. Al tiempo con una luz de las últimas horas, el sesión se el acompañadores de la historia sobre los equipos de la empresa de la Universidad Nacional del Estado, Londres-Cámara. Poco no est\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"Gustavo Petro y el Pacto\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
