{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bbe72ef-eb63-40a6-88e0-bca75023d94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_educacion = pd.read_csv(\"noticias_educacion_sample.csv\")\n",
    "df_educacion['clase'] = 0\n",
    "df_politica = pd.read_csv(\"noticias_politica_sample.csv\")\n",
    "df_politica['clase'] = 1\n",
    "df_deportes = pd.read_csv(\"noticias_deportes_sample.csv\")\n",
    "df_deportes['clase'] = 2\n",
    "df_economia = pd.read_csv(\"noticias_economia_sample.csv\")\n",
    "df_economia['clase'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d903ef95-9bf2-4757-873d-15558a2ebf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>clase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Como parte de la pol칤tica de puertas abiertas ...</td>\n",
       "      <td>2022-02-08T19:12:01.737Z</td>\n",
       "      <td>La CAN abre convocatorias para pasant칤as en Co...</td>\n",
       "      <td>La Comunidad Andina de Naciones abri칩 la posib...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>El programa, que cumple 30 a침os desde su prime...</td>\n",
       "      <td>2022-05-14T18:02:23.629Z</td>\n",
       "      <td>Colfuturo apoyar치 a 1.526 profesionales colomb...</td>\n",
       "      <td>Los beneficiarios, en su mayor칤a, realizaron e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Estudiar una carrera universitaria en Colombia...</td>\n",
       "      <td>2022-10-19T09:45:01.712Z</td>\n",
       "      <td>쮺칩mo estudiar becado en la mejor universidad ...</td>\n",
       "      <td>Seg칰n el ranking de Times Higher Education, la...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Escuche aqu칤 el episodio n칰mero 27 de Finanzas...</td>\n",
       "      <td>2021-04-07T17:56:34.238Z</td>\n",
       "      <td>Consejos para financiar con inteligencia sus e...</td>\n",
       "      <td>Si estudiar es uno de sus principales objetivo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Durante el 칰ltimo a침o de la carrera universita...</td>\n",
       "      <td>2022-04-02T18:08:22.865Z</td>\n",
       "      <td>Pruebas Saber Pro: el listado de universidades...</td>\n",
       "      <td>Las universidades p칰blicas presentaron preocup...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>495</td>\n",
       "      <td>Colombia sigue aumentando su endeudamiento ext...</td>\n",
       "      <td>2023-02-10T23:08:47.922Z</td>\n",
       "      <td>Deuda externa de Colombia represent칩 el 52,8% ...</td>\n",
       "      <td>As칤 lo deja en evidencia el m치s reciente repor...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>496</td>\n",
       "      <td>La Agencia de Estados Unidos para el Desarroll...</td>\n",
       "      <td>2022-09-28T17:00:15.603Z</td>\n",
       "      <td>Lanzan convocatoria para apoyar a m치s de mil o...</td>\n",
       "      <td>La Usaid estar치 al frente de este proceso que ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>497</td>\n",
       "      <td>La inflaci칩n es uno de los mayores retos que e...</td>\n",
       "      <td>2023-02-25T03:41:20.639Z</td>\n",
       "      <td>Controlar la inflaci칩n no ser치 tan f치cil como ...</td>\n",
       "      <td>El aumento en los precios ser치 una constante e...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>498</td>\n",
       "      <td>23 lugares ic칩nicos de C칰cuta fueron decorados...</td>\n",
       "      <td>2022-12-07T17:16:46.317Z</td>\n",
       "      <td>Reapertura econ칩mica en la frontera: artesanas...</td>\n",
       "      <td>C칰cuta prepara la Ruta Navide침a luego de haber...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>499</td>\n",
       "      <td>Durante las 칰ltimas semanas los bancos se han ...</td>\n",
       "      <td>2023-03-14T19:22:40.773Z</td>\n",
       "      <td>Tras anuncio del Gobierno Petro, el Banco Agra...</td>\n",
       "      <td>La ministra de Agricultura, Cecilia L칩pez, les...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1933 rows 칑 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                            content  \\\n",
       "0         0  Como parte de la pol칤tica de puertas abiertas ...   \n",
       "1         1  El programa, que cumple 30 a침os desde su prime...   \n",
       "2         2  Estudiar una carrera universitaria en Colombia...   \n",
       "3         3  Escuche aqu칤 el episodio n칰mero 27 de Finanzas...   \n",
       "4         4  Durante el 칰ltimo a침o de la carrera universita...   \n",
       "...     ...                                                ...   \n",
       "1928    495  Colombia sigue aumentando su endeudamiento ext...   \n",
       "1929    496  La Agencia de Estados Unidos para el Desarroll...   \n",
       "1930    497  La inflaci칩n es uno de los mayores retos que e...   \n",
       "1931    498  23 lugares ic칩nicos de C칰cuta fueron decorados...   \n",
       "1932    499  Durante las 칰ltimas semanas los bancos se han ...   \n",
       "\n",
       "                          date  \\\n",
       "0     2022-02-08T19:12:01.737Z   \n",
       "1     2022-05-14T18:02:23.629Z   \n",
       "2     2022-10-19T09:45:01.712Z   \n",
       "3     2021-04-07T17:56:34.238Z   \n",
       "4     2022-04-02T18:08:22.865Z   \n",
       "...                        ...   \n",
       "1928  2023-02-10T23:08:47.922Z   \n",
       "1929  2022-09-28T17:00:15.603Z   \n",
       "1930  2023-02-25T03:41:20.639Z   \n",
       "1931  2022-12-07T17:16:46.317Z   \n",
       "1932  2023-03-14T19:22:40.773Z   \n",
       "\n",
       "                                               headline  \\\n",
       "0     La CAN abre convocatorias para pasant칤as en Co...   \n",
       "1     Colfuturo apoyar치 a 1.526 profesionales colomb...   \n",
       "2     쮺칩mo estudiar becado en la mejor universidad ...   \n",
       "3     Consejos para financiar con inteligencia sus e...   \n",
       "4     Pruebas Saber Pro: el listado de universidades...   \n",
       "...                                                 ...   \n",
       "1928  Deuda externa de Colombia represent칩 el 52,8% ...   \n",
       "1929  Lanzan convocatoria para apoyar a m치s de mil o...   \n",
       "1930  Controlar la inflaci칩n no ser치 tan f치cil como ...   \n",
       "1931  Reapertura econ칩mica en la frontera: artesanas...   \n",
       "1932  Tras anuncio del Gobierno Petro, el Banco Agra...   \n",
       "\n",
       "                                            description  clase  \n",
       "0     La Comunidad Andina de Naciones abri칩 la posib...      0  \n",
       "1     Los beneficiarios, en su mayor칤a, realizaron e...      0  \n",
       "2     Seg칰n el ranking de Times Higher Education, la...      0  \n",
       "3     Si estudiar es uno de sus principales objetivo...      0  \n",
       "4     Las universidades p칰blicas presentaron preocup...      0  \n",
       "...                                                 ...    ...  \n",
       "1928  As칤 lo deja en evidencia el m치s reciente repor...      3  \n",
       "1929  La Usaid estar치 al frente de este proceso que ...      3  \n",
       "1930  El aumento en los precios ser치 una constante e...      3  \n",
       "1931  C칰cuta prepara la Ruta Navide침a luego de haber...      3  \n",
       "1932  La ministra de Agricultura, Cecilia L칩pez, les...      3  \n",
       "\n",
       "[1933 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_educacion, df_politica, df_deportes, df_economia]).dropna().reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b8110-f05d-4426-b661-681a8bdbe7c5",
   "metadata": {},
   "source": [
    "# BERT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3271a388-c2e6-4411-9792-e049b39ba9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "85/85 [==============================] - 83s 454ms/step - loss: 1.3964 - sparse_categorical_accuracy: 0.2631 - val_loss: 1.3889 - val_sparse_categorical_accuracy: 0.2552\n",
      "Epoch 2/4\n",
      "85/85 [==============================] - 35s 413ms/step - loss: 1.3213 - sparse_categorical_accuracy: 0.3422 - val_loss: 1.1680 - val_sparse_categorical_accuracy: 0.5034\n",
      "Epoch 3/4\n",
      "85/85 [==============================] - 35s 409ms/step - loss: 0.8203 - sparse_categorical_accuracy: 0.6319 - val_loss: 0.6617 - val_sparse_categorical_accuracy: 0.7483\n",
      "Epoch 4/4\n",
      "85/85 [==============================] - 35s 409ms/step - loss: 0.5342 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.5438 - val_sparse_categorical_accuracy: 0.8034\n",
      "19/19 [==============================] - 2s 123ms/step - loss: 0.5328 - sparse_categorical_accuracy: 0.8241\n",
      "\n",
      "Test loss: 0.5328, Test accuracy: 0.8241\n",
      "19/19 [==============================] - 5s 121ms/step\n",
      "Class 0: Precision: 0.83, Recall: 0.89, F1 score: 0.86\n",
      "Class 1: Precision: 0.90, Recall: 0.59, F1 score: 0.72\n",
      "Class 2: Precision: 0.94, Recall: 1.00, F1 score: 0.97\n",
      "Class 3: Precision: 0.67, Recall: 0.81, F1 score: 0.73\n",
      "\n",
      "Predicted class for example text: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 1. Load and prepare your dataset\n",
    "df = df[['content', 'clase']].dropna().reset_index(drop=True)\n",
    "\n",
    "# 2. Split into train/val/test\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['clase'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['clase'], random_state=42)\n",
    "\n",
    "# 3. Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# 4. Tokenization function\n",
    "def encode_texts(texts, labels):\n",
    "    tokens = tokenizer(\n",
    "        list(texts),\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    return tokens, tf.convert_to_tensor(labels)\n",
    "\n",
    "# 5. Encode splits\n",
    "train_tokens, train_labels = encode_texts(train_df['content'], train_df['clase'])\n",
    "val_tokens, val_labels = encode_texts(val_df['content'], val_df['clase'])\n",
    "test_tokens, test_labels = encode_texts(test_df['content'], test_df['clase'])\n",
    "\n",
    "# 6. Create tf.data.Dataset\n",
    "def make_tf_dataset(tokens, labels, batch_size=16, shuffle=False):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(tokens), labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(1000)\n",
    "    return dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "tf_train = make_tf_dataset(train_tokens, train_labels, shuffle=True)\n",
    "tf_val = make_tf_dataset(val_tokens, val_labels)\n",
    "tf_test = make_tf_dataset(test_tokens, test_labels)\n",
    "\n",
    "# 7. Load BERT model\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=4)\n",
    "\n",
    "# 8. Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "# 9. Train\n",
    "model.fit(tf_train, validation_data=tf_val, epochs=4)\n",
    "\n",
    "# 10. Evaluate\n",
    "results = model.evaluate(tf_test)\n",
    "print(f\"\\nTest loss: {results[0]:.4f}, Test accuracy: {results[1]:.4f}\")\n",
    "\n",
    "# 11. Predict on test set\n",
    "y_test = test_labels.numpy()\n",
    "logits = model.predict(tf_test).logits\n",
    "y_pred = np.argmax(logits, axis=1)\n",
    "\n",
    "# 12. Compute precision, recall, F1 score for each class\n",
    "num_classes = len(set(y_test))\n",
    "for i in range(num_classes):\n",
    "    class_predicted = [1 if x == i else 0 for x in y_pred]\n",
    "    class_real = [1 if x == i else 0 for x in y_test]\n",
    "    precision = precision_score(class_real, class_predicted, zero_division=0)\n",
    "    recall = recall_score(class_real, class_predicted, zero_division=0)\n",
    "    f1 = f1_score(class_real, class_predicted, zero_division=0)\n",
    "    print(f\"Class {i}: Precision: {precision:.2f}, Recall: {recall:.2f}, F1 score: {f1:.2f}\")\n",
    "\n",
    "# 13. Optional: Predict on a new sentence\n",
    "test_text = [\"La universidad abri칩 una nueva convocatoria para becas internacionales.\"]\n",
    "encoded = tokenizer(test_text, truncation=True, padding=True, max_length=128, return_tensors=\"tf\")\n",
    "logits = model(encoded).logits\n",
    "probs = tf.nn.softmax(logits, axis=-1)\n",
    "predicted_class = tf.argmax(probs, axis=1).numpy()[0]\n",
    "print(f\"\\nPredicted class for example text: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7e036c-2e4b-41b6-a527-a2521e7ba377",
   "metadata": {},
   "source": [
    "# GPT-2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "349874e1-68aa-49e1-91dd-b241974eab08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 14:46:20.916509: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-22 14:46:20.932744: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747925180.952720   88939 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747925180.958945   88939 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747925180.974985   88939 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747925180.975010   88939 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747925180.975012   88939 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747925180.975014   88939 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-22 14:46:20.980636: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa9303f90184483a0b9884cda4458a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1933 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_88939/1029234103.py:51: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1452' max='1452' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1452/1452 02:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.340800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.941900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.821800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.681700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.596400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.401800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.375100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.359700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.324500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.294600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>3.175700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>3.205600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>3.189300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>3.149500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "游닇 Generated Text Example:\n",
      "Como parte de la pol칤tica, las oportunidades especialmente para el pasado 15 de julio en la primera final de la selecci칩n del lugar, conocupaci칩n y un trino de los grandes grandes que se habilidades. El trino de los grandes se han varios afectados para el a침o de los parte de los colombianos de los est\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import torch\n",
    "\n",
    "# 1. Load your dataset\n",
    "df = df[['content']].dropna().reset_index(drop=True)\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# 2. Load tokenizer and prepare text\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"content\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "\n",
    "# 3. Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# 4. Data collator for causal LM\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# 5. Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=True,\n",
    "    logging_steps=100,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# 6. Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# 7. Train the model\n",
    "trainer.train()\n",
    "\n",
    "# 8. Save the model\n",
    "trainer.save_model(\"./gpt2-finetuned\")\n",
    "tokenizer.save_pretrained(\"./gpt2-finetuned\")\n",
    "\n",
    "# 9. Generate new text (inference)\n",
    "def generate_text(prompt, max_length=100, temperature=0.9):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    input_ids = input_ids.to(model.device)\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Example generation\n",
    "print(generate_text(\"Como parte de la pol칤tica\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88d520fb-d1e5-49a7-b637-c720daa15f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gustavo Petro y el Pacto Hist칩rico m치s de SEMANA por el poco de nada por el Gobierno. Al tiempo con una luz de las 칰ltimas horas, el sesi칩n se el acompa침adores de la historia sobre los equipos de la empresa de la Universidad Nacional del Estado, Londres-C치mara. Poco no est\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(\"Gustavo Petro y el Pacto\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
